{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion MNIST Dataset Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the dataset to be usable in pytorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "mnist_datasets_train = datasets.FashionMNIST(root='./data',train=True,download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "mnist_datasets_test = datasets.FashionMNIST(root='./data',train=False,download=True,transform=torchvision.transforms.ToTensor())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the training dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 256\n",
    "\n",
    "train_iter = DataLoader(mnist_datasets_train,batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X,y = next(iter(train_iter))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_iter = DataLoader(mnist_datasets_test,batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test,y_test = next(iter(test_iter))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising and understanding the dimensionality of the input images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of each input image is torch.Size([256, 1, 28, 28]) The number of input channels is 1\n",
      "The output labels are as follows tensor([9, 4, 8, 4, 0, 8, 0, 5, 5, 4, 5, 9, 3, 5, 0, 6, 8, 5, 4, 4, 1, 2, 2, 9,\n",
      "        7, 2, 7, 1, 0, 1, 4, 9, 4, 0, 8, 1, 1, 1, 8, 5, 1, 8, 6, 1, 6, 8, 8, 2,\n",
      "        5, 5, 5, 1, 8, 3, 3, 6, 4, 7, 7, 9, 4, 0, 3, 7, 5, 5, 9, 7, 9, 2, 8, 4,\n",
      "        1, 0, 5, 0, 7, 4, 9, 2, 3, 1, 8, 4, 8, 8, 7, 3, 7, 3, 9, 2, 7, 9, 8, 9,\n",
      "        4, 0, 5, 1, 1, 3, 5, 5, 5, 5, 0, 1, 0, 8, 6, 0, 5, 3, 7, 1, 0, 5, 5, 3,\n",
      "        5, 8, 0, 4, 0, 3, 0, 4, 5, 2, 2, 4, 0, 4, 5, 8, 1, 4, 1, 5, 2, 5, 1, 9,\n",
      "        5, 8, 5, 0, 7, 5, 3, 5, 9, 2, 6, 4, 6, 4, 0, 9, 0, 0, 4, 3, 4, 1, 6, 8,\n",
      "        1, 4, 9, 1, 2, 4, 3, 4, 5, 1, 6, 3, 9, 8, 6, 5, 4, 7, 0, 4, 8, 7, 5, 0,\n",
      "        9, 4, 1, 7, 0, 3, 8, 6, 9, 9, 9, 8, 6, 8, 2, 1, 7, 8, 1, 0, 1, 5, 4, 7,\n",
      "        5, 4, 3, 3, 0, 0, 5, 1, 4, 6, 5, 7, 7, 6, 6, 8, 7, 5, 9, 7, 7, 2, 8, 8,\n",
      "        6, 9, 0, 5, 9, 0, 8, 2, 7, 3, 8, 1, 0, 4, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'The dimensions of each input image is {X.size()} The number of input channels is {X.size()[1]}')\n",
    "print(f'The output labels are as follows {y}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example Image and corresponding label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x243f2cfe8f0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].squeeze(),cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Uses the LeNet Architecture\n",
    "Could try a different architecture and use to convolution layers size by side before pooling for down sampling\n",
    "\n",
    "- Worry about the weight and bias initialization in order to prevent over fitting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,num_channels,num_outputs):\n",
    "        super(CNN,self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        #Create the first convolution -> ReLu -> Pool layer (note the structure of this can be changed)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=num_channels,out_channels=6,kernel_size=5,padding=1,stride=1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #Create the Second convolution,relu, pooling layer\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #initialize the only fully connected -> ReLu layer\n",
    "        self.linear = torch.nn.Linear(in_features=256,out_features=84)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "\n",
    "        #Initialize a second fully connected -> ReLu layer\n",
    "        self.linear1 = torch.nn.Linear(in_features=84,out_features=16)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "\n",
    "        #Final Softmax stage for classification\n",
    "        self.linear2 = torch.nn.Linear(in_features=16,out_features=num_outputs)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #Pass the input image into the first convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        #Pass the input image into the second convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        #Pass through the 1st fully connected layer\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        #Pass through the 2nd fully connected layer\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        #Pass the output to the softmax classifier to get the output\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=256, out_features=84, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (linear1): Linear(in_features=84, out_features=16, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN(num_channels=1,num_outputs=10)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the loss and the optimizer functionality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Crete the loss component\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the optimizer term\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=2.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a metric for calculating the Accuracy of the network on the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "        cmp = (y_hat.type(y.dtype) == y)\n",
    "        return float(torch.sum(cmp))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a function for training the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def train_model(model,loss,optimizer,X,y):\n",
    "    model.train()\n",
    "\n",
    "    num_epochs = 300\n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = model(X)\n",
    "        l = loss(y_hat,y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train_model(model,loss,optimizer,X,y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.79296875"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(X),y)/len(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
